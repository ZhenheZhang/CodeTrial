{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def getPredict(self, x, w, b):\n",
    "        return np.matmul(w, x.transpose()) + b\n",
    "\n",
    "\n",
    "class Loss():\n",
    "    def __init__(self) -> None:\n",
    "        self.w_gradient = 0.0\n",
    "        self.b_gradient = 0.0\n",
    "\n",
    "    def L1(self, x, y, y_pred, N):\n",
    "        if y - y_pred >= 0:\n",
    "            self.w_gradient += -x * (1 / N)\n",
    "            self.b_gradient += -1 * (1 / N)\n",
    "        elif y - y_pred < 0:\n",
    "            self.w_gradient += x * (1 / N)\n",
    "            self.b_gradient += 1 * (1 / N)\n",
    "        return [self.w_gradient, self.b_gradient]\n",
    "\n",
    "            \n",
    "class Optimizer():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def SGD(self, w_in, b_in, w_gradient, b_gradient, learning_rate):\n",
    "        w_update = w_in - (learning_rate * w_gradient)\n",
    "        b_update = b_in - (learning_rate * b_gradient)\n",
    "        return[w_update, b_update]\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, data, lr, iter_num, w_init, b_init):\n",
    "        self.train_data = data\n",
    "        self.learning_rate = lr\n",
    "        self.max_iter_num = iter_num\n",
    "        self.init_weight = w_init\n",
    "        self.init_bias = b_init\n",
    "        self.weight_dim = w_init.shape[0]\n",
    "\n",
    "    def train(self):\n",
    "        w_upt = self.init_weight\n",
    "        b_upt = self.init_bias\n",
    "        for i in range(self.max_iter_num):\n",
    "            [w_upt, b_upt] = self.epoch_train(w_iter=w_upt, b_iter=b_upt)\n",
    "            if i % 500 == 0:\n",
    "                print(\"iteration[{}], val_acc is {:.4f}\".format(i, self.calcValAcc(w=w_upt, b=b_upt)))\n",
    "        return [w_upt, b_upt]\n",
    "\n",
    "\n",
    "    def epoch_train(self, w_iter, b_iter):\n",
    "        N = float(len(self.train_data))\n",
    "        model = Model()\n",
    "        loss = Loss()\n",
    "        optim = Optimizer()\n",
    "\n",
    "        for index in range(0, len(self.train_data)):\n",
    "            x = self.train_data[index, 0 : self.weight_dim]\n",
    "            y = self.train_data[index, -1]\n",
    "\n",
    "            # Get prediction\n",
    "            y_pred = model.getPredict(x, w_iter, b_iter)\n",
    "            # Calc L1 loss\n",
    "            loss.L1(x, y, y_pred, N)\n",
    "        \n",
    "        # Calc SGD\n",
    "        w_grad = loss.w_gradient\n",
    "        b_grad = loss.b_gradient\n",
    "        update = optim.SGD(w_iter, b_iter, w_grad, b_grad, self.learning_rate)\n",
    "        return update        \n",
    "\n",
    "    def calcValAcc(self, w, b):\n",
    "        model = Model()\n",
    "        val_acc = 0.0\n",
    "\n",
    "        for index in range(0, len(self.train_data)):\n",
    "            x = self.train_data[index, 0 : self.weight_dim]\n",
    "            y = self.train_data[index, -1]\n",
    "            y_pred = model.getPredict(x, w, b)\n",
    "            val_acc += np.abs(y - y_pred)\n",
    "        # # Visualization\n",
    "        # plt.cla()\n",
    "        # plt.scatter(self.train_data[:, 0], self.train_data[:, 1])\n",
    "        # plt.plot(self.train_data[:, 0], model.getPredict(self.train_data[:, 0], w, b), 'r-', lw=5)\n",
    "        # plt.show()\n",
    "        return val_acc / float(len(self.train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at weight=[0. 0.] bias=0.0 val_acc=0.5426908921354588\n",
      "### START TRAINING ###\n",
      "iteration[0], val_acc is 0.5352\n",
      "iteration[500], val_acc is 0.1441\n",
      "iteration[1000], val_acc is 0.1441\n",
      "iteration[1500], val_acc is 0.1441\n",
      "iteration[2000], val_acc is 0.1441\n",
      "iteration[2500], val_acc is 0.1441\n",
      "iteration[3000], val_acc is 0.1441\n",
      "iteration[3500], val_acc is 0.1441\n",
      "iteration[4000], val_acc is 0.1441\n",
      "iteration[4500], val_acc is 0.1441\n",
      "iteration[5000], val_acc is 0.1441\n",
      "### TRAINING STOPPED ###\n",
      "Trained 5001 iterations: weight=[0.51081404 0.26529206] bias=0.09860000000000045 val_acc=0.1440758009699697\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # data simulation\n",
    "    w_tgt = np.array([0.5, 0.3])\n",
    "    b_tgt = 0.1\n",
    "    noise = 0.2 * np.random.randn(100)\n",
    "    points = np.zeros((100, w_tgt.shape[0] + 1))\n",
    "    points[:, 0 : w_tgt.shape[0]] = np.random.randn(100, w_tgt.shape[0])\n",
    "    points[:, -1] = np.matmul(w_tgt, points[:, 0 : w_tgt.shape[0]].transpose()) + b_tgt + noise   # ground truth: y = 0.5 * x + 0.1\n",
    "\n",
    "    # parameters setup\n",
    "    learning_rate = 0.01\n",
    "    w_init = np.zeros_like(w_tgt)\n",
    "    b_init = 0.0\n",
    "    inter_num = 5001\n",
    "    lr_trainer = Trainer(points, learning_rate, inter_num, w_init, b_init)\n",
    "\n",
    "    # print\n",
    "    print(\"Starting gradient descent at weight={} bias={} val_acc={}\".format(w_init, b_init, lr_trainer.calcValAcc(w_init, b_init)))\n",
    "\n",
    "    # training loop\n",
    "    print(\"### START TRAINING ###\")\n",
    "    [w, b] = lr_trainer.train()\n",
    "    print(\"### TRAINING STOPPED ###\")\n",
    "    print(\"Trained {} iterations: weight={} bias={} val_acc={}\".format(inter_num, w, b, lr_trainer.calcValAcc(w, b)))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f46f602a9fb80e9e2e49bf94182631528f06d646b9958424248b38c6e6bffff3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
